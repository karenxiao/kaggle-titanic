{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Competition\n",
    "###Karen Xiao\n",
    "\n",
    "5/6/2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Loading in Data\n",
    "First, we will read in the data file `titanic.csv` and store it as a Numpy array. We will be using the `csv` package to read and write csv files and the `Numpy` package for some of its array and other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'pclass', 'ticket', 'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest']\n",
      "['1' 'Allen, Miss. Elisabeth Walton' 'female' '29' '0' '0' '1' '24160'\n",
      " '211.3375' 'B5' 'S' '2' '' 'St Louis, MO']\n"
     ]
    }
   ],
   "source": [
    "import csv as csv \n",
    "import numpy as np\n",
    "\n",
    "raw_csv = csv.reader(open('train.csv', 'rb')) \n",
    "\n",
    "# skip the header\n",
    "header = raw_csv.next()\n",
    "\n",
    "# read in rows from the raw_csv file and store in data variable         \n",
    "data=[]                        \n",
    "for row in raw_csv:     \n",
    "    data.append(row)       \n",
    "data = np.array(data) \n",
    "\n",
    "print header\n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Plotting the Data\n",
    "Now that we have the data loaded in, we can plot some initial data just to get a sense of what we have. Here we will use a plotting library called `Matplotlib`. As a first hypothesis, we might look at the survival chances based on gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of women who survived: 0.742038216561\n",
      "Percentage of men who survived: 0.188908145581\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAiMAAAEZCAYAAABFIyXnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAHmVJREFUeJzt3XucXVV99/HPlwRogQJSaIAQDVVRQxWxmlotNg/2oVTb\n",
       "oH0qIFYpor2opbbegm0fY/FSrbWVp7X2QiVSEgxaEGxVLmW04gVvUSQg8GgKCSZcGhRQrvn1j73H\n",
       "nExmJieQM/vM5PN+veaVfVl77XVmcs58Z621905VIUmS1JVdum6AJEnauRlGJElSpwwjkiSpU4YR\n",
       "SZLUKcOIJEnqlGFEkiR1yjCinU6Sv0vyJx234ewkZ3TZBkkaFoYRDYUkv5Dkc0nuTHJHks8mefog\n",
       "zlVVv1dVbxtE3dvTjPbrEUtyXJJVSb6X5LYklyeZvyPqlqSpMLvrBkhJ9gY+DvwOsBLYHTgKuO9h\n",
       "1BWAmuK7+SWZXVUPbu9hO+C8jwOWAS+sqiuS7AUcAzz0SOuWpKliz4iGwWE0+eHD1bi3qi6tqqsB\n",
       "kixNcs5o4STzk2xKsku7PpLkbUmuBO4B3pDkS70nSPKHST7WLv9oiCTJtUme31Nudtu78NR2fXGS\n",
       "a5JsTHJFkif2lF2T5I1JvgHclWRWkjclWZvk+0muS3L0JK97/ySXtGVHkjy6rfdvk7xnTPsvSvLa\n",
       "cep4KvCdqrqC5pt4d1X9a1Xd3B6XJEuS3Jjk9iQfTvKodt/fJflIzzneleSySdorSQNhGNEw+Bbw\n",
       "UBsSjh39Zdmjn16O3wReAewFfAB4QttrMOok4Nye+kbrXA68uKfcLwO3VtWqJIe1+08D9gf+Hbg4\n",
       "SW+P4onArwD7Ao8DXg08var2pumhWDNBewO8BPiztu5VPe07G3jxaC9Pkv2B5/bs7/UV4IlJ3ptk\n",
       "Udsz0us0YDHwHOAgYCPwt+2+PwKenOTkJEcBLwdeNkF7JWlgDCPqXFXdBfwCTUD4R+DWJB9L8lNt\n",
       "kW0NZxRwdlVdW1Wbqur7wMdoQ0aSxwNPAC7qOWa0zhXA4iQ/1q6f1G4DOAH4eFVdXlUPAe8Bfhx4\n",
       "Vs95z6yqdVV1H83QyO7A4Ul2raqbqurbk7T741X12aq6H/hj4OeTzK2qLwHfowkg0ASeK6rqtq1e\n",
       "eNV3gEXAXJohrtuSfDDJnm2R3wH+pKpuqaoHgLcCv5Fkl6r6IfBS4K+Ac4DXVNUtk7RXkgbCMKKh\n",
       "UFXXVdUpVTUP+BngYOCvt6OKm8es9/Z4nARcUFX3jnPeG4FraQLJHsCvtcdC05NwU0/Zas8zd7zz\n",
       "tnW9FlgKbEiyIslBE7S3gLU9x94D/DfN6wb4EE1vD+2/5zCBqvpiVZ1QVT9FM9fmOTThBmA+cEE7\n",
       "zLQRWA08CMxpj70KGA1M5090DkkaJMOIhk5VfYtmUubPtJvuAfboKXLgeIeNWb8MOCDJETQ9C8u3\n",
       "PuRHVtAEl+OA1T29GbcAjxkt1A6bzAPWTXTeqlpRVUe1xxXwrknOO6+n7r2A/dpzAvwLcFzb/icC\n",
       "F05ST+/5vwxcABzebroJOLaqHtXztUdVfbc976uB3drzvrGfc0jSjmYYUeeSPCHJHyWZ267PowkH\n",
       "n2+LrAKek2Rekn2A08erpnelHZI4n2Zo5VHApROVBc6jmSvyu2w5L2Ml8PwkRyfZFXgdcC/wuQle\n",
       "x2Ft2d1prgS6l4mvagnwvCTPTrIbcAbw+apa17Z/LfBlmh6Sj7TDQOOd89lJXpHkgHb9iTS9O19o\n",
       "i3wAeEfP5NgDkiwebW973pfQzBV5Yxt+JGlKGUY0DO4Cfg74YpK7aULIN2h++VNVlwIfbrd9CbiY\n",
       "rXtCxpvkupxm3sX5VbVpTNkfla+q9TQB4+fb84xuv55miOT/AbcBzwd+bZJLeHcH3tmW/S7NxNTx\n",
       "gtNoG84F3gLcARzJ5mGZUcuAJzPJEA1wJ80E1auT3AV8AvhX4N3t/vfRzJW5JMn3ab63C5PMauv9\n",
       "86q6uh1iejNwThu8JGnKZNC3Y0iyL/BPNN3GBZwC3EDzof8YmqsNjq+qO9vyp9PM6n8IOK2qLhlo\n",
       "A6Uh1V7h8i9V9ZhtFpakaWwqekbeB/x7VT0JeApwHbAEuLSqDgMub9dJsoDmCoYFwLHA+0fvJSHt\n",
       "TNreidfSXF0kSTPaQH/Rt+P7R1XVPwNU1YNV9T2abuVlbbFlwAva5eOAFVX1QFWtAW4EFg6yjdKw\n",
       "SfIkmvuBzGH7riiSpGlp0LeDP5T2vgfAETQ3aHotMKeqNrRlNtBeZkhzWeMXeo5fy5aXUUozXlVd\n",
       "S3PzNknaKQx6CGQ28DTg/VX1NJpLNJf0Fmjv3TDZxJUpfcaIJEmaWoPuGVkLrG3vKAnwEZqrC9Yn\n",
       "ObCq1rc3hbq13b+OnnsvAIew5T0dSGI4kaSHoaoe8cMZpUGYiqtpPgO8oqquT7KUzTevuqOq3pVk\n",
       "CbBvVS1pJ7Aup5knMpfmxlWP630Ca5LaWd9QSZZW1dKu2yFNVzvze2hn/uzU8Bt0zwjA7wPntjd2\n",
       "+v80l/bOAlYmOZX20l6AqlqdZCWbb1n9qql+FLwkSZpaAw8jVfV14Bnj7PqlCcq/A3jHQBslSZKG\n",
       "hvfwmF5Gum6ANM2NdN0ASVsb+JyRHc1xT0nafn52aphNxZwRSZJ2GK+qnL4mCsSGEUnStGMvz/Qz\n",
       "WYg0jEiakH+BDj9/KWsmMIxImpRpZHiZQjRTeDWNJEnqlGFEkiRtIclRSa6bsvN5aa+kiSSZZp8Q\n",
       "O5fQ/5yRmfTZOd5rmYr5TVPx/UuyieYxKN8e9Lmm2mT/B50zIkmaIQaZR6Y0x01F6JlVVQ8N+jz9\n",
       "cphGkqQdKMmaJK9L8vUkdyY5L8nuPftfmeSGJHck+Vj79PrRB8sCfD3JXUleNE7dj0vy6bbe25Kc\n",
       "126fn2RTkl16yo60z4AjyW8luTLJe5PcDpyRZGOSw3vKH5DkB0n2T7Ioyc3t9jclOX9MO96X5H3t\n",
       "8j5JzkpyS5K1Sc7obUc/DCOSJO1YBbwI+GXgUOApwG8BJDma5vlrLwIOAv4LOA+gqp7THv+UqvqJ\n",
       "qjqfrZ0BfLKq9qV5uv2Z22hHb3fRQpoH1v4U8GfAvwIv7tl/PDBSVbePqec84HlJ9mpfw6y2/ee2\n",
       "+88G7gceCxwJHAO8YpJ2bcUwIknSjndmVa2vqo3AxcBT2+0vAc6qqlVVdT9wOvDzSR7dZ733A/OT\n",
       "zK2q+6vqc9vRpluq6m+ralNV3QssB07s2X9Su20LVfVfwFeBF7abjgZ+UFVXJZkD/Arwh1X1w6q6\n",
       "DfjrMfVuk2FEkqQdb33P8g+BPdvl0d4QAKrqHuAOml6OfryRZk7JVUm+meSU7WjTzWPWR4A9kixM\n",
       "Mh84ArhggmOXs7kX5SQ294o8BtgV+G477LMR+ABwwHa0ywmskiRNoVuA+aMrSfYEfhJY18/BVbUB\n",
       "+O322GcDlyX5NHBXW2QP4O52+cCxh4+p66EkK2lCxq3AxW04Gs9HgL9MMhd4AfDMdvvNwH3AT1bV\n",
       "pn5ew3jsGZEkafBGr5BZAZyS5Ih2Uus7gC9U1U3t/g00cy/GryR5UZJD2tU7aQLGpnZ4ZB3w0iSz\n",
       "krx8snp6jA7VjDtEM6qtf4Rmfsi3q+pb7fbvApcA703yE0l2SfLYJM+ZqK7xGEYkSTNEBvj1iPxo\n",
       "ImlVXQ78KfBRml6SQ9lyfsVSYFk75PEb49T1dOALSe4CPgacVlVr2n2vBN4A3A4sAK4crw1bNKzq\n",
       "KpqelIOAT4zT7l7LgeeydWh5GbAbsBr4b+B8tu6VmZQ3PZM0IW96Nty86Zmmk8l+bvaMSJKkThlG\n",
       "JElSpwwjkiSpU4YRSZLUKcOIJEnqlGFEkiR1yjAiSZI6ZRiRJEmdMoxIkjTNJPn3JC/tuh07indg\n",
       "lTQh78A63LwD65bbBn3emfL960qnd2BNsibJN5J8LclV7bb9klya5PoklyTZt6f86UluSHJdkmMG\n",
       "3T5J0sxQA/yaSklmT/EpOzcVwzQFLKqqI6tqYbttCXBpVR0GXN6uk2QBcALNA36OBd6fxKEkSdK0\n",
       "keRNSdYm+X77h/XRSc5OckZPmUVJbu5ZX5PkjUm+AdzdLp8/pt73JXlfuzyS5NQkuye5M8nhPeUO\n",
       "SPKDJPu367+aZFX78L0rkzx54N+E7TRVv+jHdsssBpa1y8uAF7TLxwErquqB9imENwILkSRpGkjy\n",
       "BODVwNOram/gGGAN/XWynAj8CrAPcB7wvCR7tfXOAl4EnNuWLaCq6j6aJwC/uKee44GRqro9yZHA\n",
       "WTRP9N0P+HvgoiS7PcKXukNNVc/IZUm+nOSV7bY5VbWhXd4AzGmXDwbW9hy7Fpg7BW2UJGlHeAjY\n",
       "HTg8ya5VdVNVfbvdN9mckwLOrKp1VXVfVd0EfBV4Ybv/aOAHVXXVOMcupwkyo05qtwH8NvD3VfWl\n",
       "anwIuA945sN6dQMyFWHk2VV1JE3ae3WSo3p3VjODdrK06Pw5SdK0UFU3Aq8FlgIbkqxIclCfh988\n",
       "Zn05m3s8TmJzr8hYI8AeSRYmmQ8cAVzQ7nsM8Lp2iGZjko3AIUC/bZoSA58kU1Xfbf+9LckFNMMu\n",
       "G5IcWFXr2x/SrW3xdcC8nsMPabdtIcnSntWRqhoZRNslabpKsghY1HEzdkpVtQJYkeQnaIZF3gV8\n",
       "H9ijp9iB4x06Zv0jwF8mmUsznWHc3oyqeijJSprgcitwcVXd0+6+CXh7Vb3j4b6eqTDQMJJkD2BW\n",
       "Vd2VZE+asbO3AhcBJ9P8gE4GLmwPuQhYnuS9NMMzjwe26pKqqqWDbLckTXftH2kjo+tJ3tJZY3Yi\n",
       "SQ6j+UP6SprhkHtphmdW0fRQvI1mGOe126qr/SN+BDgb+HZVfWvs6XqWlwMfA24H3tyz/R+BC5Jc\n",
       "BnyJJhAtAj5dVXdv58sbmEH3jMyh+SaMnuvcqrokyZeBlUlOpZnYczxAVa1u091q4EHgVTXdboQi\n",
       "SerEkNwEZHfgncCTgAdoQslvAxuBX6L5nfcdmoDxR33Utxz4EPCGcfb96PdjVV2V5G6a4ZdP9Gz/\n",
       "Sjtf829o/sD/IfCfwKe372UNljc9kzQhb3o23LzpmaaTTm96JkmSNBnDiCRJ6pRhRJIkdcowIkmS\n",
       "OmUYkSRJnTKMSJKkTu10jymWJE1/SbzqfAYxjEiSphXvMTLzGEYkTcpPfUmDZhiRtA32hg8vo6Jm\n",
       "BiewSpKkThlGJElSpwwjkiSpU4YRSZLUKcOIJEnqlGFEkiR1yjAiSZI6ZRiRJEmdMoxIkqROGUYk\n",
       "SVKnDCOSJKlThhFJktQpw4gkSeqUYUSSJHXKMCJJkjplGJEkSZ0yjEiSpE4ZRiRJUqcMI5IkqVMD\n",
       "DyNJZiX5WpKL2/X9klya5PoklyTZt6fs6UluSHJdkmMG3TZJktS9qegZ+QNgNVDt+hLg0qo6DLi8\n",
       "XSfJAuAEYAFwLPD+JPbcSJI0ww30l32SQ4DnAf8EpN28GFjWLi8DXtAuHwesqKoHqmoNcCOwcJDt\n",
       "kyRJ3Rt0z8NfAW8ANvVsm1NVG9rlDcCcdvlgYG1PubXA3AG3T5IkdWz2oCpO8qvArVX1tSSLxitT\n",
       "VZWkxts3WmSCupf2rI5U1cjDbackzUTt5+6ijpsh9WVgYQR4FrA4yfOAHwP2TnIOsCHJgVW1PslB\n",
       "wK1t+XXAvJ7jD2m3baWqlg6u2ZI0/bV/pI2Mrid5S2eNkbZhYMM0VfXmqppXVYcCJwL/UVUvBS4C\n",
       "Tm6LnQxc2C5fBJyYZLckhwKPB64aVPskSdJwGGTPyFijQy5/DqxMciqwBjgeoKpWJ1lJc+XNg8Cr\n",
       "qmqyIRxJkjQDZLr9vk9SVZVtl5T0SDVzuqbXZ8TOJfT7eehnp4aZ9/GQJEmdMoxIkqROGUYkSVKn\n",
       "DCOSJKlThhFJktQpw4gkSeqUYUSSJHXKMCJJkjplGJEkSZ0yjEiSpE4ZRiRJUqcMI5IkqVOGEUmS\n",
       "1CnDiCRJ6pRhRJIkdcowIkmSOmUYkSRJnTKMSJKkThlGJElSpwwjkiSpU4YRSZLUqW2GkSSX97NN\n",
       "kiTp4Zg90Y4kPw7sARyQZL+eXXsDcwfdMEmStHOYMIwAvwP8AXAw8JWe7XcBfzPIRkmSpJ1Hqmry\n",
       "AslpVXXmFLVnm5JUVaXrdkg7gyQFk39GqEuh389DPzs1zLYZRgCSPAuYT09PSlV9aHDNmrQtvqGk\n",
       "KWIYGXaGEc0Mkw3TAJDkX4CfBlYBD/Xs6iSMSJKkmWWbYQT4WWBB9dOFMmSav+o0zPxLTZLUz31G\n",
       "vgkctL0VJ/mxJF9MsirJ6iTvbLfvl+TSJNcnuSTJvj3HnJ7khiTXJTlme885nvJraL8kSYL+JrCO\n",
       "AE8FrgLuazdXVS3eZuXJHlX1gySzgc8CrwcWA7dX1buTvAl4VFUtSbIAWA48g+bS4cuAw6pq05g6\n",
       "+x73TDL9unN2IsGekWHnnJFh55wRzQz9DNMsfbiVV9UP2sXdgFnARpow8ovt9mXACLAEOA5YUVUP\n",
       "AGuS3AgsBL7wcM8vSZKG3zbDSFWNPNzKk+wCfBV4LPB3VXVNkjlVtaEtsgGY0y4fzJbBYy3eXE2S\n",
       "pBmvn6tp7mZzP+1uwK7A3VW197aObYdYnppkH+BTSf7XmP21jUmm4+5LsrRndeSRBCZJmomSLAIW\n",
       "ddwMqS/99IzsNbrc9nQsBp65PSepqu8l+TeaK3M2JDmwqtYnOQi4tS22DpjXc9gh7bbx6lu6PeeX\n",
       "pJ1N+0fayOh6krd01hhpG7brqb1VtamqLgSO3VbZJPuPXinTPufmfwNfAy4CTm6LnQxc2C5fBJyY\n",
       "ZLckhwKPp5k0K0mSZrB+hmn+T8/qLjS9Gz/so+6DgGVtb8ouwDlVdXmSrwErk5wKrAGOB6iq1UlW\n",
       "AquBB4FXTcd7m0iSpO3Tz6W9Z7N57saDNAHiH6vq1omOGSQv7Z05vLR3+Hlp77Dz0l7NDH09m2aY\n",
       "GEZmDsPI8DOMDDvDiGaGbc4ZSTIvyQVJbmu/PprkkKlonCRJmvn6mcD6QZrJpQe3Xxe32yRJkh6x\n",
       "fuaMfL2qjtjWtqniMM3M4TDN8HOYZtg5TKOZoZ+ekTuSvDTJrCSzk/wmcPugGyZJknYO/YSRU2gu\n",
       "v10PfBd4UbtNkiTpEevnQXl/BrysqjYCJNkPeA/w8kE2TJIk7Rz66Rk5YjSIAFTVfwNPG1yTJEnS\n",
       "zqSfMJK2N2R0ZT9g1uCaJEmSdib9DNP8JfD59lbtoZkz8vaBtkqSJO00+roDa5LDgaNprvH7j6pa\n",
       "PeiGTdIWL+2dIby0d/h5ae+w89JezQzeDl6dMYwMP8PIsDOMaGboZ86IJEnSwBhGJElSpwwjkiSp\n",
       "U4YRSZLUKcOIJEnqlGFEkiR1yjAiSZI6ZRiRJEmdMoxIkqROGUYkSVKnDCOSJKlThhFJktQpw4gk\n",
       "SeqUYUSSJHXKMCJJkjplGJEkSZ0aaBhJMi/JFUmuSfLNJKe12/dLcmmS65NckmTfnmNOT3JDkuuS\n",
       "HDPI9kmSpO6lqgZXeXIgcGBVrUqyF/AV4AXAKcDtVfXuJG8CHlVVS5IsAJYDzwDmApcBh1XVpp46\n",
       "q6rS5/kH+Or0SAXo92epbiQp8F00vNL3e2h7PjulqTbQnpGqWl9Vq9rlu4FraULGYmBZW2wZTUAB\n",
       "OA5YUVUPVNUa4EZg4SDbKEmSujVlc0aSzAeOBL4IzKmqDe2uDcCcdvlgYG3PYWtpwoskSZqhZk/F\n",
       "Sdohmo8Cf1BVdyWbewqrqpqu4AlttS/J0p7Vkaoa2UFNlaQZIckiYFHHzZD6MvAwkmRXmiByTlVd\n",
       "2G7ekOTAqlqf5CDg1nb7OmBez+GHtNu2UFVLB9hkSZr22j/SRkbXk7yls8ZI2zDoq2kCnAWsrqq/\n",
       "7tl1EXByu3wycGHP9hOT7JbkUODxwFWDbKMkSerWoK+m+QXgM8A32DzccjpNwFgJPBpYAxxfVXe2\n",
       "x7wZeDnwIM2wzqfG1OnVNDOEV9MMP6+mGXZeTaOZYaBhZBAMIzOHYWT4GUaGnWFEM4N3YJUkSZ0y\n",
       "jEiSpE4ZRiRJUqcMI5IkqVOGEUmS1CnDiCRJ6pRhRJIkdcowIkmSOmUYkSRJnTKMSJKkThlGJElS\n",
       "pwwjkiSpU4YRSZLUKcOIJEnqlGFEkiR1yjAiSZI6ZRiRJEmdMoxIkqROGUYkSVKnDCOSJKlThhFJ\n",
       "ktQpw4gkSeqUYUSSJHXKMCJJkjplGJEkSZ0yjEiSpE4ZRiRJUqcMI5IkqVMDDSNJ/jnJhiRX92zb\n",
       "L8mlSa5PckmSfXv2nZ7khiTXJTlmkG2TJEnDYdA9Ix8Ejh2zbQlwaVUdBlzerpNkAXACsKA95v1J\n",
       "7LmRJGmGG+gv+6r6T2DjmM2LgWXt8jLgBe3yccCKqnqgqtYANwILB9k+SZLUvS56HuZU1YZ2eQMw\n",
       "p10+GFjbU24tMHcqGyZJkqZep8MgVVVATVZkqtoiSZK6MbuDc25IcmBVrU9yEHBru30dMK+n3CHt\n",
       "tq0kWdqzOlJVI4NoqCRNV0kWAYs6bobUlzSdEwM8QTIfuLiqntyuvxu4o6relWQJsG9VLWknsC6n\n",
       "mScyF7gMeFyNaWCSqqr0ee4Bvzo9EgH6/VmqG0nKDsphlr7fQ9vz2SlNtYH2jCRZAfwisH+Sm4H/\n",
       "C/w5sDLJqcAa4HiAqlqdZCWwGngQeNXYICJJkmaegfeM7Gj2jMwc9owMP3tGhp09I5oZvI+HJEnq\n",
       "lGFEkiR1yjAiSZI61cWlvVPKAVJJkobbjA8jTr4bZkZFSZLDNJIkqWOGEUmS1CnDiCRJ6pRhRJIk\n",
       "dcowIkmSOmUYkSRJnTKMSJKkThlGJElSpwwjkiSpU4YRSZLUKcOIJEnqlGFEkiR1yjAiSZI6ZRiR\n",
       "JEmdMoxIkqROGUYkSVKnDCOSJKlThhFJktQpw4gkSeqUYUSSJHXKMCJJkjplGJEkSZ0yjEiSpE4N\n",
       "XRhJcmyS65LckORNXbdHkiQN1lCFkSSzgL8BjgUWAC9O8qRuWzVMRrpugDTNjXTdAEnjGKowAiwE\n",
       "bqyqNVX1AHAecFzHbRoiI103QJrmRrpugKRxDFsYmQvc3LO+tt0mSZJmqGELI9V1AyRJ0tSa3XUD\n",
       "xlgHzOtZn0fTO7KFJNsRWvKIGzVc3tp1A3ao7ftZqhu+h4aZ7yHNBKkanv/HSWYD3wKeC9wCXAW8\n",
       "uKqu7bRhkiRpYIaqZ6SqHkzyGuBTwCzgLIOIJEkz21D1jEiSpJ3PsE1gndGSnJZkdZJzBlT/0iSv\n",
       "G0Td0kyTZFGSi7tuh6QhG6bZCfwe8NyqumVA9dvNJUmaduwZmSJJPgD8NPDJJG9OclaSLyb5apLF\n",
       "bZnfSnJhkkuSfCfJa5K8vi3z+SSPasu9MslVSVYl+UiSHx/nfI9N8okkX07ymSRPmNpXLA1ekvnt\n",
       "4yM+mORbSc5NckySK5Ncn+QZ7dfn2vfRlUkOG6eePZP889j3pKSpYRiZIlX1uzRXCC0C9gT+o6p+\n",
       "Djga+Iske7RFDwdeCDwDeDvw/ap6GvB54GVtmY9W1cKqeipwLXBq76naf/8B+P2qejrwBuD9g3pt\n",
       "UsceC7wHeCLwBOCEqno28HrgzTTvkaPa99FbgHeMU8cfA5dP8J6UNGAO00y9AL8MLE7y+nbb7sCj\n",
       "aYLEFVV1D3BPkjuB0THtq4GntMtPTvI2YB9gL+CTW5wg2RN4FnB+8qN7ROw2mJcjde47VXUNQJJr\n",
       "gMva7d8E5gP7AuckeRzNe2zXceo4Bvi1Me/JeTS3GpA0YIaR7vx6Vd3QuyHJzwH39Wza1LNebP55\n",
       "nQ0srqqrk5xM09vSaxdgY1UduaMbLQ2hse+Z+3uWZwNn0PR6vDDJY5j4ATVbvSclTQ2HabrxKeC0\n",
       "0ZUko6Gh31td7gWsT7Ir8JtsHpoJzeXadwHfSfIbbf1J8pTxq5JmtAB70wyRApwyQbmJ3pOSpoBh\n",
       "ZGpV+3UGsGuSbyT5JpvvTz26v7f82GMB/hT4IvBZmvHw8cq8BDg1ySqa7mon5GmmGnsVWe/6JuAv\n",
       "gHcm+SrNzRTHe49N9J6UNAW86ZkkSeqUPSOSJKlThhFJktQpw4gkSeqUYUSSJHXKMCJJkjplGJEk\n",
       "SZ0yjEiSpE4ZRiRJUqcMI1Kf2sfM/1uSVUmuTnJ8kp9NMpLky0k+meTAJPu0j7U/rD1uRZJTt1W/\n",
       "JO2sfFCe1L9jgXVV9XyAJHsDn6B5aOEdSU4A3l5VpyZ5DXB2kjOBfarqrO6aLUnDzdvBS31K8njg\n",
       "EuDDwMeBO4ErgW+3RWYBt1TVsW35fwB+HXhKVd2ydY2SJLBnROpbVd3QPs31+cDbgCuAa6rqWWPL\n",
       "JtkFeBJwD7Afm58aK0kawzkjUp+SHATcW1XnAu8BFgL7J3lmu3/XJAva4n8IXEPz9OQPJjH4S9IE\n",
       "/ICU+vdk4C+SbALuB34PeAg4M8k+NO+nv0ryIHAq8IyquifJZ4A/AZZ202xJGm7OGZEkSZ1ymEaS\n",
       "JHXKMCJJkjplGJEkSZ0yjEiSpE4ZRiRJUqcMI5IkqVOGEUmS1CnDiCRJ6tT/AIyeCB8x6zpnAAAA\n",
       "AElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1352e1050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define \"mask\" variables that can be applied on the data to filter on females in column 4\n",
    "female_mask = data[0::,4] == \"female\"\n",
    "male_mask = data[0::,4] != \"female\"\n",
    "\n",
    "women = data[female_mask,1].astype(np.float)     \n",
    "men = data[male_mask,1].astype(np.float)\n",
    "\n",
    "# calculate percentages\n",
    "print \"Percentage of women who survived: %s\" % (np.sum(women) / np.size(women))\n",
    "print \"Percentage of men who survived: %s\" % (np.sum(men) / np.size(men))\n",
    "\n",
    "# plot the data\n",
    "width = .5\n",
    "index = np.arange(2) + .25\n",
    "survived = [np.sum(women), np.sum(men)]\n",
    "died = [np.size(women) - np.sum(women), np.size(men) - np.sum(men)] \n",
    "\n",
    "plot_died = plt.bar(index, died, width, color='b')\n",
    "plot_survived = plt.bar(index, survived, width, color='r', bottom=died)   \n",
    "\n",
    "plt.title('Survivors by Sex')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('sex')\n",
    "plt.xticks(index+.25, ['female', 'male'])\n",
    "plt.legend((plot_died, plot_survived), ('not survive', 'survive'), bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##A Simple Gender-based Model\n",
    "Now that we've looked at this dimension of the data, we can create a very basic model to predict whether a passenger will survive purely based off of their gender. Clearly, this model is not going to give us the best results, but it works as an initial exercise.\n",
    "\n",
    "The code below will read in the data, apply our model, and output our prediction to a csv file in a format ready for submission to Kaggle. Unlike before, instead of using a Numpy array to store and manipulate our data, we will be using a Pandas DataFrame, which has some more sophisticated capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in the data using the Pandas .read_csv function\n",
    "raw_data = pd.read_csv('train.csv', header=0)\n",
    "\n",
    "# create prediction DataFrame with 'Survived' set to 1 if the passenger is female\n",
    "predictions = pd.DataFrame({'PassengerId': raw_data.PassengerId, 'Survived': raw_data.Sex.map({'female': 1, 'male': 0})})\n",
    "\n",
    "# write the resulting predictions to a csv file\n",
    "predictions.to_csv('genderpredictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Cleaning the Data\n",
    "At this point, we probably want to do something a little more complex and use more than just one paramter to make our predictions. However, taking a closer look at our data reveals a few gaps. Notice when we run the `df.info()` command, we find that `Age, Fare,` and `Cabin` are missing some values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision now is what to fill the missing data with. We obviously don't want to just guess or fill it with random values because that will introduce a lot of noise into our data. Other common options are to fill the gaps with the mean or median values of that parameter. But we're going to get a little fancier. \n",
    "\n",
    "To fill in the missing `Age` data, we're going to find the age typical to each gender and passenger class using a 2 x 3 reference table (for 2 genders and 3 passenger classes). For `Fares`, we might expect the median fare to be fairly closely correlated with the passenger class, so we calculate the median fares for each class and fill in the data appropriately. Below we have written a function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "clean_missing_data\n",
    "\n",
    "Given a DataFrame, fill in the missing Age and Fare data with median values\n",
    "\n",
    "Inputs\n",
    "------\n",
    "df : DataFrame\n",
    "    The DataFrame object read in from the Kaggle Titanic train and test csv files\n",
    "\"\"\"    \n",
    "\n",
    "def clean_missing_data(df):\n",
    "\n",
    "    # ceate new column converting Sex (female, male) stored as strings to Gender (0, 1) stored as ints\n",
    "    df['Gender'] = df.Sex.map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "    # create our reference table for median ages based on passenger class and gender\n",
    "    median_ages = np.zeros((2, 3))\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            median_ages[i, j] = df[(df.Gender == i) & (df.Pclass == j+1)]['Age'].dropna().median()\n",
    "\n",
    "    # fill in null values\n",
    "    for index, row in df[df['Age'].isnull()].iterrows():\n",
    "        df.loc[index,'Age'] = median_ages[row.Gender][row.Pclass-1]\n",
    "\n",
    "    # calculate median fares for each passenger class\n",
    "    median_fares = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        median_fares[i] = df[df.Pclass == i+1]['Fare'].dropna().median()\n",
    "\n",
    "    # fill in null values\n",
    "    for index, row in df[df['Fare'].isnull()].iterrows():\n",
    "        df.loc[index,'Fare'] = median_fares[row.Pclass-1] \n",
    "        \n",
    "    return df\n",
    "\n",
    "# read in our test and train datasets and store as DataFrames\n",
    "train_csv = pd.read_csv('train.csv', header=0)\n",
    "test_csv = pd.read_csv('test.csv', header=0)\n",
    "\n",
    "# fill in the missing data\n",
    "train_clean = clean_missing_data(train_csv)\n",
    "test_clean = clean_missing_data(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this exercise, and to more easily use the scikit-learn package, we don't want any non-numeric values. So using the `df.dtypes`, we find that the `Name, Sex, Ticket, Cabin,` and `Embarked` columns are of type object (which means string in Pandas). For now, since we don't need them, we will remove these columns. For the purposes of our next exercise, we will also remove `PassengerId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep a copy of the passenger ids for later\n",
    "passenger_ids = test_clean.PassengerId.values\n",
    "\n",
    "# drop unneeded (non-numerical) columns\n",
    "train_clean = train_clean.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1) \n",
    "test_clean = test_clean.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a nice and clean dataset! The last step is to convert this to a Numpy array so it is consummable by `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-9186b0ba614f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print out the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# convert to Numpy array\n",
    "train_data = train_clean.values\n",
    "test_data = test_clean.values\n",
    "\n",
    "# print out the result\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a clean data set that's in a consummable Numpy array format, we can start running it against some models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Logistic Regression\n",
    "Logistic regression usually works well for binary classifications. In this case, we are predicting if a passenger survived or didn't survive, so logistic regression is probably a good one to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# create the logistic regression object which will include all the parameters for the fit\n",
    "regression = LogisticRegression()\n",
    "\n",
    "# fit the training data to the Survived labels \n",
    "regression = regression.fit(train_data[0::,1::],train_data[0::,0])\n",
    "\n",
    "# run on the test data\n",
    "predictions = regression.predict(test_data)\n",
    "\n",
    "# format to be submittable to Kaggle and write out to csv\n",
    "predictions_file = open(\"regressionpredictions.csv\", \"wb\")\n",
    "file_writer = csv.writer(predictions_file)\n",
    "file_writer.writerow([\"PassengerId\",\"Survived\"])\n",
    "file_writer.writerows(zip(passenger_ids, predictions.astype(int)))\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Decision Trees\n",
    "Decision trees are also simple and tend to work well with classification problems, so we might also try a decision tree implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier = classifier.fit(train_data[0::,1::],train_data[0::,0])\n",
    "predictions = classifier.predict(test_data)\n",
    "\n",
    "# format to be submittable to Kaggle and write out to csv\n",
    "predictions_file = open(\"treepredictions.csv\", \"wb\")\n",
    "file_writer = csv.writer(predictions_file)\n",
    "file_writer.writerow([\"PassengerId\",\"Survived\"])\n",
    "file_writer.writerows(zip(passenger_ids, predictions.astype(int)))\n",
    "predictions_file.close()\n",
    "\n",
    "# plot the tree created\n",
    "from sklearn.externals.six import StringIO\n",
    "with open(\"tree.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(classifier, out_file=f)\n",
    "# then in the terminal, run \"dot -Tpng tree.dot -o tree.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Forest\n",
    "Decision trees don't always work well with certain datasets because they can overfit to the training set, so we might use an ensemble learning method like random forests that create many different decision trees and predict the result based on the results of the individual trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit(train_data[0::,1::],train_data[0::,0])\n",
    "predictions = forest.predict(test_data)\n",
    "\n",
    "# format to be submittable to Kaggle and write out to csv\n",
    "predictions_file = open(\"forestpredictions.csv\", \"wb\")\n",
    "file_writer = csv.writer(predictions_file)\n",
    "file_writer.writerow([\"PassengerId\",\"Survived\"])\n",
    "file_writer.writerows(zip(passenger_ids, predictions.astype(int)))\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
